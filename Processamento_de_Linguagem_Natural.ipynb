{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONXbWsoC3ok9zraBuf8A1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanaBoaventura/Processamento-de-Linguagem-Natural/blob/main/Processamento_de_Linguagem_Natural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Processamento de Linguagem Natural**"
      ],
      "metadata": {
        "id": "bykU0nPlY87p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ler(nome_arquivo):\n",
        "  arquivo = open(nome_arquivo, 'r', encoding='utf-8')\n",
        "  conteudo_arq = arquivo.read()\n",
        "  arquivo.close()\n",
        "  return conteudo_arq\n",
        "\n",
        "  texto = ler('https://drive.google.com/file/d/1cjsprOU1yom5hC57wq8qpKIGUbQHJUiJ/view?usp=drive_link')\n",
        "  print(len(texto))\n",
        "\n",
        "def buscador(alvo, texto):\n",
        "  texto = texto.replace('\\n', ' ')\n",
        "  texto = texto.replace('\\t', ' ')\n",
        "\n",
        "  ocorrencias = []\n",
        "\n",
        "  encontrado_aqui = texto.find(alvo, 0)\n",
        "\n",
        "  while encontrado_aqui > 0:\n",
        "    pos_inicial = encontrado_aqui - (40 - len(alvo))\n",
        "    trecho = texto[pos_inicial: pos_inicial + 80]\n",
        "\n",
        "    ocorrencias.append(trecho)\n",
        "\n",
        "    encontrado_aqui = texto.find(alvo, encontrado_aqui + 1)\n",
        "\n",
        "  return ocorrencias\n",
        "\n",
        "resultados = buscador('peito', texto)\n",
        "\n",
        "for trecho in resultados:\n",
        "    print(trecho)\n",
        "\n",
        "palavras = texto.split()\n",
        "\n",
        "def limpar(lista):\n",
        "  lixo = '.,:;?!\"´`^~()[]{}/\\|@#$%¨&*-'\n",
        "  quase_limpo = [x.strip(lixo).lower() for x in lista]\n",
        "  return [x for x in quase_limpo if x.isalpha() or '-' not in x]\n",
        "\n",
        "teste = \"Corre-se atrás do carro, corre se o carro for embora.\"\n",
        "word = teste.split()\n",
        "print(word)\n",
        "\n",
        "print(limpar(word))\n",
        "\n",
        "print(len(palavras))\n",
        "palavras = limpar(palavras)\n",
        "print(len(palavras))\n",
        "\n",
        "vocabulario = set(palavras)\n",
        "len(vocabulario)\n",
        "\n",
        "riqueza = len(vocabulario) / len(palavras)\n",
        "riqueza\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "def ocorrencias(lista_palavras):\n",
        "  dicionario = defauldict(int)\n",
        "  for p in lista_palavras:\n",
        "    dicionario[p] += 1\n",
        "\n",
        "  return dicionario\n",
        "\n",
        "dic = ocorrencias(palavras)\n",
        "mf = sorted(dic.items(), key=lambda tupla:tupla[1],reverse=True)[:50]\n",
        "for palavra, n in mf:\n",
        "  print(palavra,'\\t',n)\n",
        "\n",
        "dic\n",
        "tupla([0],[1])\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "vazias = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "frequentes_plenas = [x for x in mf if x[0].lower() not in vazias]\n",
        "frequentes_plenas"
      ],
      "metadata": {
        "id": "9p52yYVBZove"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}